<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>portfolio_en</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
</head>
<body>
<h1 id="minjae-cho">Minjae Cho</h1>
<h2 id="personal-information">Personal Information</h2>
<figure>
<img src="./assets/profile.jpg" alt="Profile" />
<figcaption aria-hidden="true">Profile</figcaption>
</figure>
<p>üìÖ <strong>Date of Birth</strong>: January 15, 2000</p>
<p>üìß <strong>Email</strong>: devcho3356@gmail.com</p>
<p>üåê <strong>GitHub</strong>: <a
href="https://github.com/SGT-Cho">SGT-Cho</a></p>
<p>üìù <strong>Velog</strong>: <a
href="https://velog.io/@sgt-cho/posts">sgt-cho/posts</a></p>
<h2 id="about-me">üë®‚Äçüíª About Me</h2>
<p><strong>One-line Introduction</strong></p>
<p>I‚Äôm Minjae Cho, a developer who embraces growth and challenges. My
goal is to use technology to make people‚Äôs lives more convenient.</p>
<p><strong>Goals/Vision</strong></p>
<p>I strive to become a developer who solves problems efficiently
through diverse tech stacks and project experiences, always prioritizing
user experience.</p>
<h2 id="education">üéì Education</h2>
<ul>
<li><strong>Incheon National University</strong>, Bachelor of Computer
Science, Expected Graduation: August 2024</li>
</ul>
<h2 id="skills">‚öôÔ∏è Skills</h2>
<ul>
<li><strong>Programming Languages</strong>:
<ul>
<li><strong>C</strong>, <strong>C++</strong>,
<strong>Python</strong></li>
</ul></li>
<li><strong>Libraries &amp; Frameworks</strong>:
<ul>
<li><strong>NumPy</strong>, <strong>Pandas</strong>,
<strong>PyTorch</strong>, <strong>TensorFlow</strong>,
<strong>Keras</strong>, <strong>scikit-learn</strong>,
<strong>OpenCV</strong>, <strong>Matplotlib</strong>,
<strong>Seaborn</strong>, <strong>XGBoost</strong></li>
</ul></li>
<li><strong>Tools &amp; Platforms</strong>:
<ul>
<li><strong>Jupyter</strong>, <strong>Google Colab</strong>,
<strong>Amazon AWS</strong>, <strong>Google Cloud</strong>,
<strong>Docker</strong>, <strong>Rhinoceros</strong>,
<strong>Anaconda</strong>, <strong>Huggingface</strong></li>
</ul></li>
</ul>
<h2 id="projects">üìÇ Projects</h2>
<h3 id="aiffelthon">AIFFELTHON</h3>
<figure>
<img src="./assets/aiffelton.png" alt="aiffelton.png" />
<figcaption aria-hidden="true">aiffelton.png</figcaption>
</figure>
<ul>
<li><strong>Description</strong>: A project conducted during AIFFEL, a
bootcamp by ‚Äúmodulabs‚Äù.</li>
<li><strong>Tech Stack</strong>: Jupyter Notebook, TensorFlow, NumPy,
Pandas, Matplotlib</li>
<li><strong>GitHub Link</strong>: <a
href="https://github.com/SGT-Cho/AIFFELTHON">AIFFELTHON</a></li>
</ul>
<h3
id="realtimecartracking-computervision-">RealTimeCarTracking-ComputerVision-</h3>
<figure>
<img src="./assets/cardetection.png" alt="cardetection.png" />
<figcaption aria-hidden="true">cardetection.png</figcaption>
</figure>
<ul>
<li><strong>Description</strong>: Real-time vehicle tracking using
YOLO.</li>
<li><strong>Tech Stack</strong>: Jupyter Notebook, OpenCV, YOLO</li>
<li><strong>GitHub Link</strong>: <a
href="https://github.com/SGT-Cho/RealTimeCarTracking-ComputerVision-">RealTimeCarTracking-ComputerVision-</a></li>
</ul>
<h3 id="llm-project">LLM project</h3>
<ul>
<li><strong>Description</strong>: Developed an LLM that can operate in
local environments (including RAG and Finetuning).</li>
<li><strong>Tech Stack</strong>: Python, Langchain, LLaMA, PHI4,
Deepseek R1, PyTorch, Transformers</li>
<li><strong>GitHub Link</strong>: <a
href="https://github.com/SGT-Cho/LLM">LLM Project</a></li>
</ul>
<h3 id="building-crack-detection">Building Crack Detection</h3>
<p><img src="./assets/bldgcrack.jpg" alt="Original Image" /> <img
src="./assets/bldgcrack2.png" alt="Example Prediction" /></p>
<ul>
<li><strong>Description</strong>: Crack detection in concrete structures
using computer vision.</li>
<li><strong>Tech Stack</strong>: Python, PyTorch, Transformers</li>
<li><strong>GitHub Link</strong>: <a
href="https://github.com/SGT-Cho/BldgCrackDetection">BLDG_CrackDetection</a></li>
</ul>
<h3 id="speech-recognition">Speech Recognition</h3>
<ul>
<li><strong>Description</strong>: Speech recognition using Google
Cloud‚Äôs Speech-to-Text API.</li>
<li><strong>Tech Stack</strong>: Python, GCP Speech-to-Text API (minimal
external libraries)</li>
<li><strong>GitHub Link</strong>: <a
href="https://github.com/SGT-Cho/speech_recognition">Speech_recognition</a></li>
</ul>
<h3 id="llama-3.1-8b-finetuning">Llama 3.1 8b Finetuning</h3>
<p><img src="./assets/finetuned2.png" alt="finetuned" /> <img
src="./assets/finetuned1.png" alt="unfinetuned" /></p>
<p>(First image: Finetuned model, Second image: Base model)</p>
<ul>
<li><strong>Description</strong>: Finetuned META‚Äôs Llama 3.1 8b model
using Korean cuisine datasets.</li>
<li><strong>Tech Stack</strong>: Langchain, Llama, PEFT, Lora</li>
<li><strong>Huggingface Link</strong>: <a
href="https://huggingface.co/mobilelife">Llama3.1_8b_korean_food_finetuned</a></li>
</ul>
<h3
id="reinforcement-learningbased-super-mario-bros-training-madmario">Reinforcement
Learning‚Äìbased Super Mario Bros Training (MadMario)</h3>
<p><img src="./assets/mario.png" alt="playing" /><br />
- <strong>Description</strong>: Trained an agent to play Super Mario
Bros using PPO and parallel environments.<br />
- <strong>Key Details</strong>:<br />
- Used <code>stable-baselines3</code> PPO with up to 8 parallel
<code>SubprocVecEnv</code> instances<br />
- Optimized for Mac MPS (Metal Performance Shaders)<br />
- Resolved Gym/Gymnasium API compatibility for stable VecEnv
training<br />
- <strong>Tech Stack</strong>: Python, Stable-Baselines3, Gymnasium,
PyTorch</p>
<h3 id="malicious-url-detection-dacon">Malicious URL Detection
(DACON)</h3>
<ul>
<li><strong>Description</strong>: Developed a phishing URL detection
model for the DACON competition by preprocessing and analyzing ~180,000
URLs.<br />
</li>
<li><strong>Key Contributions</strong>: Engineered domain-based and
character n-gram features; fused BERT embeddings with a CNN + XGBoost
ensemble.<br />
</li>
<li><strong>Tech Stack</strong>: Python, Pandas, scikit-learn, PyTorch,
Transformers, XGBoost<br />
</li>
<li><strong>Achievement</strong>: Achieved an F1-score of 0.969</li>
</ul>
<h3 id="discord-llm-bot-development-deployment">Discord LLM Bot
Development &amp; Deployment</h3>
<p><img src="./assets/discordbot.png" alt="discordbot" /><br />
- <strong>Description</strong>: Built a Discord chat-assistant bot
powered by a local LLM (Gemma3).<br />
- <strong>Key Features</strong>: Performs web scraping on user queries
and uses RAG (Retrieval-Augmented Generation) for informed
responses.<br />
- <strong>Tech Stack</strong>: Python, discord.py, LangChain, Docker,
Llama.cpp<br />
- <strong>Deployment</strong>: Packaged as a Docker container and hosted
on GitHub for continuous availability</p>
<h3 id="pathmaker-destination-recommendation-app">Pathmaker Destination
Recommendation App</h3>
<p><img src="./assets/pathmaker.png" alt="pathmaker" /><br />
- <strong>Description</strong>: Travel destination recommendation
service combining Flutter frontend and FastAPI backend.<br />
- <strong>Key Contributions</strong>: Designed PostgreSQL schema;
implemented RESTful APIs; integrated Google Places API; developed
user-preference recommendation algorithm.<br />
- <strong>Recommendation Algorithm</strong>: Computes weighted
similarity scores based on distance, ratings, and category weight.<br />
- <strong>Tech Stack</strong>: Flutter (Dart), FastAPI, PostgreSQL,
SQLAlchemy, Google Maps &amp; Places API</p>
<h3 id="automated-youtube-shorts-generation-using-runpod">Automated
YouTube Shorts Generation using Runpod</h3>
<p><img src="./assets/runpod_workflow.png" alt="runpod_workflow" /> <img
src="./assets/youtube_shorts_example.png"
alt="youtube_shorts_example" /></p>
<ul>
<li><strong>Description</strong>: Developed a fully automated workflow
system that generates short-form video content based on scripts using
RunPod‚Äôs Stable Diffusion 3. The system handles everything from image
generation and TTS voice-over to video editing and saving.</li>
<li><strong>Key Features</strong>:
<ul>
<li>Automated script generation via Local LLM: Randomly selects a topic
from a user-defined list ‚Üí Calls Local LLM API ‚Üí Outputs script.</li>
<li>Image generation using RunPod SD3 API: Converts the generated script
into image prompts to create visuals with SD3.</li>
<li>Dia 1.6b TTS for voice-over: Processes the script content with TTS
to create narration audio.</li>
<li>Video synthesis and text overlay with FFmpeg: Combines SD3 images +
TTS audio ‚Üí Automated video creation (1080x1920, including text).</li>
</ul></li>
<li><strong>Tech Stack</strong>: Runpod (Stable Diffusion 3), Local LLM,
Dia 1.6b TTS, FFmpeg</li>
</ul>
<h3
id="ai-powered-job-posting-collection-rag-analysis-system">AI-Powered
Job Posting Collection &amp; RAG Analysis System</h3>
<figure>
<img src="./assets/careers_discord_bot_jd.png"
alt="careers_discord_bot_example" />
<figcaption aria-hidden="true">careers_discord_bot_example</figcaption>
</figure>
<ul>
<li><strong>Description</strong>: An intelligent system that
automatically collects job postings from major Korean IT companies and
utilizes RAG (Retrieval-Augmented Generation) technology to
intelligently search and recommend job information tailored to
user-defined criteria.</li>
<li><strong>Key Features</strong>:
<ul>
<li>Real-time monitoring and automated information gathering from 10+
company career sites.</li>
<li>Semantic-based job posting search leveraging RAG technology.</li>
<li>Personalized real-time job alerts delivered via a Discord Bot.</li>
</ul></li>
<li><strong>Tech Stack</strong>: Python, Selenium, Beautiful Soup,
AsyncIO, PostgreSQL, ChromaDB, OpenAI API, Hugging Face Transformers,
LangChain, Sentence Transformers, Docker, GitHub Actions, Discord Bot
API, PyPDF2, APScheduler</li>
</ul>
<h2 id="certifications-courses">üìú Certifications &amp; Courses</h2>
<ul>
<li>K-Digital Training [AI Innovation School ‚ÄúAIFFEL‚Äù: Core Course] -
[2022-11-21~2023-05-08]</li>
<li>Total: 112 days (840 hours)</li>
</ul>
<h2 id="awards-activities">üèÜ Awards &amp; Activities</h2>
<ul>
<li>Encouragement Award, Incheon National University Computer Science
Graduation Project Presentation (2024)</li>
<li>Served in KATUSA (Korean Augmentation to the U.S. Army):
<ul>
<li>Driver for Command Sergeant Major, Special Operations Command Korea
(SOCKOR), Nov 2020 - May 2022</li>
</ul></li>
</ul>
<h2 id="language-skills">üåè Language Skills</h2>
<ul>
<li>Language Training: Canada (Aug 2010 ‚Äì Nov 2010)<br />
</li>
<li>TOEIC: 955 (expired)<br />
</li>
<li>TOEIC Speaking: 160 (expired)<br />
</li>
<li>OPIc: IM2 (valid)<br />
</li>
<li>TOEFL: 86 (valid)<br />
</li>
<li>Significantly improved speaking skills during KATUSA service.</li>
</ul>
</body>
</html>
